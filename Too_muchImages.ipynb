{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff87d9f6",
   "metadata": {},
   "source": [
    "# Détection de Pneumonie à l'aide de SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20526c37",
   "metadata": {},
   "source": [
    "\n",
    "Ce notebook utilise un classifieur SVM pour détecter la pneumonie à partir d'images de radiographies pulmonaires. \n",
    "Les images sont pré-traitées pour isoler les poumons et sont ensuite utilisées pour entraîner et tester le modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eda79e",
   "metadata": {},
   "source": [
    "\n",
    "## Importation des bibliothèques et définition des chemins\n",
    "Dans cette section, nous importons les bibliothèques nécessaires et définissons les chemins vers les ensembles de données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "732dfb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# Chemins vers les ensembles de données\n",
    "path_train_malades = 'C:/Users/Mentu/Documents/IA/Zoidberg/train/PNEUMONIA'\n",
    "path_train_non_malades = 'C:/Users/Mentu/Documents/IA/Zoidberg/train/NORMAL'\n",
    "path_test_malades = 'C:/Users/Mentu/Documents/IA/Zoidberg/test/PNEUMONIA'\n",
    "path_test_non_malades = 'C:/Users/Mentu/Documents/IA/Zoidberg/test/NORMAL'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dcd745",
   "metadata": {},
   "source": [
    "\n",
    "## Fonction de recadrage des images\n",
    "Cette fonction recadre la zone des poumons dans une image pour se concentrer uniquement sur la région d'intérêt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba76e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour recadrer la zone des poumons d'une image\n",
    "def crop_lungs_from_image(img):\n",
    "    \"\"\"Recadre uniquement la zone des poumons d'une image.\n",
    "    :param img: image à recadrer.\n",
    "    :returns: image recadrée.\"\"\"\n",
    "    img_cv = np.array(img)\n",
    "    _, thresh = cv2.threshold(img_cv, 15, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        print(\"No contours found\")\n",
    "        return img  # Return the original image if no contours are found\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cropped_img_cv = img_cv[y:y + h, x:x + w]\n",
    "    cropped_img = Image.fromarray(cropped_img_cv)\n",
    "    return cropped_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdce19a",
   "metadata": {},
   "source": [
    "\n",
    "## Définition des fonctions utilitaires\n",
    "Nous définissons ici deux fonctions : l'une pour mesurer le temps d'exécution et l'autre pour charger les images à partir de deux dossiers différents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41c95446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour mesurer le temps d'exécution des fonctions\n",
    "def timing_function(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} a pris {end - start:.2f} secondes\")\n",
    "        return result\n",
    "    return wrapper \n",
    "\n",
    "# Fonction pour charger des images à partir de deux dossiers\n",
    "@timing_function\n",
    "def load_images_from_two_folders(folder1, folder2, image_size=(90, 90)):\n",
    "    images, labels = []\n",
    "\n",
    "    # Charger les images du premier dossier\n",
    "    for filename in os.listdir(folder1):\n",
    "        if filename.endswith('.jpeg'): # Vérifiez l'extension du fichier si nécessaire\n",
    "            img = Image.open(os.path.join(folder1, filename)).convert('L')  # Convertir en niveaux de gris\n",
    "            img = crop_lungs_from_image(img)\n",
    "            img = img.resize(image_size)\n",
    "            images.append(np.array(img).flatten())  # Aplatir l'image\n",
    "            labels.append(1)  # Étiquette 1 pour le premier dossier\n",
    "\n",
    "    # Charger les images du deuxième dossier\n",
    "    for filename in os.listdir(folder2):\n",
    "        if filename.endswith('.jpeg'):  # Vérifiez l'extension du fichier si nécessaire\n",
    "            img = Image.open(os.path.join(folder2, filename)).convert('L')  # Convertir en niveaux de gris\n",
    "            img = crop_lungs_from_image(img)\n",
    "            img = img.resize(image_size)\n",
    "            images.append(np.array(img).flatten())  # Aplatir l'image\n",
    "            labels.append(0)  # Étiquette 0 pour le deuxième dossier\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89393dde",
   "metadata": {},
   "source": [
    "\n",
    "## Chargement des images et des étiquettes puis Création et entraînement du modèle SVM\n",
    "Nous créons un pipeline avec la mise à l'échelle des données et SVM, puis entraînons le modèle avec les données d'entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "075c6d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Charger les images et les étiquettes d'entraînement\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_images, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_images_from_two_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_train_malades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_train_non_malades\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Charger les images et les étiquettes de test\u001b[39;00m\n\u001b[0;32m      5\u001b[0m test_images, test_labels \u001b[38;5;241m=\u001b[39m load_images_from_two_folders(path_test_malades, path_test_non_malades)\n",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m, in \u001b[0;36mtiming_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      4\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m a pris \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secondes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m, in \u001b[0;36mload_images_from_two_folders\u001b[1;34m(folder1, folder2, image_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;129m@timing_function\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_images_from_two_folders\u001b[39m(folder1, folder2, image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m90\u001b[39m, \u001b[38;5;241m90\u001b[39m)):\n\u001b[1;32m---> 14\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Charger les images du premier dossier\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder1):\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "# Charger les images et les étiquettes d'entraînement\n",
    "train_images, train_labels = load_images_from_two_folders(path_train_malades, path_train_non_malades)\n",
    "\n",
    "# Charger les images et les étiquettes de test\n",
    "test_images, test_labels = load_images_from_two_folders(path_test_malades, path_test_non_malades)\n",
    "\n",
    "# Créer un pipeline avec la mise à l'échelle des données et SVM\n",
    "pipeline = make_pipeline(StandardScaler(), SVC(probability=True, class_weight='balanced', kernel='rbf'))\n",
    "\n",
    "# Entraîner le modèle\n",
    "pipeline.fit(train_images, train_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30c379",
   "metadata": {},
   "source": [
    "\n",
    "## Prédiction et évaluation du modèle\n",
    "Nous effectuons des prédictions sur les données de test et affichons le rapport de classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Faire des prédictions\n",
    "predicted_labels = pipeline.predict(test_images)\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(test_labels, predicted_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890641a2",
   "metadata": {},
   "source": [
    "\n",
    "## Matrice de confusion\n",
    "Nous traçons la matrice de confusion pour visualiser les performances du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07276872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tracer la matrice de confusion\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=['Normal', 'Pneumonie'],\n",
    "       yticklabels=['Normal', 'Pneumonie'],\n",
    "       title='Matrice de Confusion',\n",
    "       ylabel='Étiquette réelle',\n",
    "       xlabel='Étiquette prédite')\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302792f8",
   "metadata": {},
   "source": [
    "\n",
    "## Courbe ROC\n",
    "Nous calculons et traçons la courbe ROC pour évaluer les performances du modèle en termes de taux de faux positifs et de vrais positifs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculer la courbe ROC et l'aire sous la courbe pour l'ensemble de test\n",
    "probabilities = pipeline.predict_proba(test_images)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(test_labels, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Tracer la courbe ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Courbe ROC (aire = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taux de faux positifs')\n",
    "plt.ylabel('Taux de vrais positifs')\n",
    "plt.title('Caractéristique de Fonctionnement du Récepteur')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
